# Python
* > for index,value in data.enumerate()
* 

# Kaynaklar
* Kitap
  - [ ] Python ile Derin Öğrenme,François Chollet
  - [ ] Derin Öğrenme, Ian Goodfellow
  - [ ] Yapay Zeka, Nils J. Nilsson
  - [ ] Machines that Think
  - [ ] Robotların Yükselişi,Martin ford
  - [ ] Yapay Öğrenme,Ethem Alpaydın
  - [ ] [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)
  - [ ] Introduction to Machine Learning With Python
  - [ ] Deep Learning Cookbook
  - [ ] Learning Tensorflow
  - [ ] Practical Stastistics for Data Scientists
  - [ ] Machine Learning with Python Cookbook
  - [ ] Hands‑On Machine Learning with Scikit‑Learn, Keras, and TensorFlow
  - [ ] Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython
  - [ ] The Elements of Statistical Learning
  - [ ] Dive into Deep Learning
  - [ ] [Better Deep Learning](https://machinelearningmastery.com/better-deep-learning/)
  - [ ] Yapay Zeka, Vasif Nabiyev
  - [ ] Artificiel Intelligence: A Modern Approach
  - [ ] deeplearningbook.org
  - [ ] Deep learning from scratch, seth weidman

* İnternet Makale
  - [ ] https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/
  - [X] https://ahmetkuzubasli.medium.com/modeliniz-neden-hala-hatal%C4%B1-bias-ve-variance-6368f36de751
  - [ ] https://xgboost.readthedocs.io/en/latest/tutorials/model.html
  - [ ] scikit-learn documentation
  - [ ] https://medium.com/visionwizard/understanding-focal-loss-a-quick-read-b914422913e7
  - [ ] [scipy lectures](http://scipy-lectures.org/)
  - [ ] https://machinelearningmastery.com/improve-deep-learning-performance/
  - [ ] https://towardsdatascience.com/accelerate-hyperparameter-tuning-217c95ca626e
  - [ ] https://www.jeremyjordan.me/gradient-descent/
  - [ ] https://deepmind.com/blog/article/population-based-training-neural-networks
  - [ ] https://machinelearningmastery.com/evaluate-skill-deep-learning-models/
  - [ ] https://machinelearningmastery.com/improve-deep-learning-performance/
  - [ ] https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
  - [ ] https://ayyucekizrak.medium.com/g%C3%B6r%C3%BCnt%C3%BC-b%C3%B6l%C3%BCtleme-segmentasyon-i%C3%A7in-derin-%C3%B6%C4%9Frenme-u-net-3340be23096b
  - [ ] https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/
  - [ ] https://www.analyticsvidhya.com/blog/2021/06/a-detailed-explanation-of-gan-with-implementation-using-tensorflow-and-keras/



* Bilimsel makale
 - [ ]  Predicting Good Probabilities with Supervised Learning
 - [ ]  [Random Search for Hyper-Parameter Optimization](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)
 - [ ]  [A Disciplined Approach To Neural Network Hyper-Parameters: Part I - Learning Rate, Batch Size, Momentum, And Weight Decay](https://arxiv.org/pdf/1803.09820.pdf)
 - [ ]  [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/pdf/1506.01186.pdf)
 - [ ]  [A Simple Weight Decay Can Improve Generalization](https://papers.nips.cc/paper/1991/file/8eefcfdf5990e441f0fb6f3fad709e21-Paper.pdf)
 - [ ]  [Random Search for Hyper-Parameter Optimization](https://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf)
 - [ ]  [A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning](http://haikufactory.com/files/bayopt.pdf)
 - [ ]  [Sequential Model-Based Optimization for General Algorithm Configuration](https://www.cs.ubc.ca/~hutter/papers/10-TR-SMAC.pdf)

* Kurs/Video
 - [X] Btkakademi makine öğrenmesi
 - [ ] Btkakademi keras
 - [ ] btkakademi tensorflow
 - [ ] Deeplearning AI
 - [ ] [Coursera Improving Deep Neural Networks](https://www.coursera.org/learn/deep-neural-network?utm_source=gg&utm_medium=sem&utm_content=01-CatalogDSA-ML1-US&campaignid=12490862811&adgroupid=119269357576&device=c&keyword=&matchtype=b&network=g&devicemodel=&adpostion=&creativeid=503940597773&hide_mobile_promo&gclid=Cj0KCQjwjPaCBhDkARIsAISZN7RmpxXjJw1pdLohAji8QfSNnL63U-4hv0Zk49Sc4XNv7BK21QNNSjkaAu75EALw_wcB)
 - [ ] [fast.ai](https://www.fast.ai/)
 - [ ] Andrew NG Kursları
 - [ ] cs231n.stanford.edu
## Hyperparameter tuning
- [ ] https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e
- [X] https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8
- [X] **https://www.jeremyjordan.me/hyperparameter-tuning/**
- [ ] https://nanonets.com/blog/hyperparameter-optimization/
- [X] https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/
- [ ] https://towardsdatascience.com/hyperparameters-optimization-526348bb8e2d
- [ ] https://towardsdatascience.com/tuning-hyperparameters-with-optuna-af342facc549
- [ ] https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/
- [ ] https://scikit-learn.org/stable/modules/grid_search.html
- [ ] https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f
- [ ] https://sigopt.com/blog/common-problems-in-hyperparameter-optimization
- [ ] [Gilles Louppe | Bayesian optimization with Scikit-Optimize](https://www.youtube.com/watch?v=DGJTEBt0d-s)
- [ ] https://towardsdatascience.com/hyperparameter-optimization-with-keras-b82e6364ca53
- [ ] https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e
- [ ] [The Number of Hidden Layers](https://www.heatonresearch.com/2017/06/01/hidden-layers.html)
- [ ] [Beginners Ask “How Many Hidden Layers/Neurons to Use in Artificial Neural Networks?”](https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e)
- [ ] [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner)
- [ ] [Hyperparameter tuning with Keras Tuner](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)
- [ ] https://towardsdatascience.com/10-hyperparameter-optimization-frameworks-8bc87bc8b7e3 
- [ ] 

## Matematik yol haritası
  1. Temel matematik
  2. Analiz
  3. Linner Cebir
  4. Olasılık
  5. İstatistik

# Araştırılacak
- [ ] Focal loss
- [ ] ada belief
- [ ] momentum nedir?
- [ ] optimizasyon kütüphaneleri
- [ ] FCBF feature selection
- [ ] Vanishing gradient
- [ ] NiftyNet
- [ ] CosineLoss